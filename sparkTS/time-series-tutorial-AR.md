# Time series analysis on surrogate data.

## Compilation notes:
Compile by typing in time series folder: sbt assembly .
Run by typing in time series folder: sbt console .

In this tutorial we are going to practice on artificially generated data
and show that we are able to successfully identify autoregressive models.

## Data specification

Let's generate some data with an order 3 Autoregressive Model.

<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val actualP = 3
</pre>
</div>
</div>

We have 3 spatial dimensions (3 sensors or data feeds).
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val d = 3
</pre>
</div>
</div>

Let's generate 10000 samples (you can also try a million for instance).
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val N = 10000L
</pre>
</div>
</div>

## Time series configuration

Let's specify that there is one millisecond between each sample.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val deltaTMillis = 1L
</pre>
</div>
</div>

Let's have an overlap between partitions of 100 ms
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val paddingMillis = 100L
</pre>
</div>
</div>

We choose to have 8 partitions
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val nPartitions = 8
</pre>
</div>
</div>

We gather all that information into the implicit val config which will be
used later on in all the calls we make.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
implicit val config = TSConfig(deltaTMillis, d, N, paddingMillis.toDouble)
</pre>
</div>
</div>

## Data generation
(1) We generate the coefficients of the model randomly and try to enforce causality.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val ARCoeffs: Array[DenseMatrix[Double]] = Array.fill(actualP){DenseMatrix.rand[Double](d, d) - (DenseMatrix.ones[Double](d, d) * 0.5)}
Stability.makeStable(ARCoeffs)
</pre>
</div>
</div>

We have the same amount of noise everywhere.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val noiseMagnitudes = DenseVector.ones[Double](d)
</pre>
</div>
</div>

Let's generate the surrogate data.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val rawTS = Surrogate.generateVAR(
  ARCoeffs,
  d,
  N.toInt,
  deltaTMillis,
  Gaussian(0.0, 1.0),
  noiseMagnitudes,
  sc)
</pre>
</div>
</div>

And put it in the overlapping data structure
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val (timeSeriesRDD: RDD[(Int, SingleAxisBlock[TSInstant, DenseVector[Double]])], _) =
  SingleAxisBlockRDD((paddingMillis, paddingMillis), nPartitions, rawTS)
</pre>
</div>
</div>

We can inspect the parameters and plot some data
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
PlotTS.showModel(ARCoeffs, Some("Actual parameters"))
PlotTS(timeSeriesRDD, Some("In Sample Data"))
</pre>
</div>
</div>

__Note:__ If at this point the plot shows there are NAN values, it means that the
model we have randomly generated is numerically unstable.
This can happen, let's just regenerate the coefficients of the model and the data.
Go back to (1) if unfortunately this has happened.

Let's take a look at the auto-correlation structure of the data we have
generated. If that correlation vanishes to 0 after lag q, the data we
see is most likely generated by an MA(q) model.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val (correlations, _) = CrossCorrelation(timeSeriesRDD, 4)
PlotTS.showModel(correlations, Some("Cross correlation"))
</pre>
</div>
</div>

Let's take a look at the partial auto-correlation structure of the data we have
generated. If that correlation vanishes to 0 after lag p, the data we
see is most likely generated by an AR(p) model.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val (partialCorrelations, _) = PartialCrossCorrelation(timeSeriesRDD,4)
PlotTS.showModel(partialCorrelations, Some("Partial cross correlation"))
</pre>
</div>
</div>

## Monovariate analysis

1. Let's fit a univariate AR model on each spatial dimension of the data
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val p = actualP
val mean = MeanEstimator(timeSeriesRDD)
val vectorsAR = ARModel(timeSeriesRDD, p, Some(mean)).map(_.covariation)
</pre>
</div>
</div>

2. Now we compute the prediction residuals (in sample).
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val residualsAR = ARPredictor(timeSeriesRDD, vectorsAR, Some(mean))
</pre>
</div>
</div>

3. We also compute the variance - covariance matrix of the residuals.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val residualSecondMomentAR = SecondMomentEstimator(residualsAR)
</pre>
</div>
</div>

4. Let's inspect the result:
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
PlotTS.showUnivModel(vectorsAR, Some("Monovariate parameter estimates"))
PlotTS(residualsAR, Some("Monovariate AR residual error"))
</pre>
</div>
</div>

## Multivariate analysis

1. Let's fit a multivariate AR model taking the information of all sensors
jointly into account.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val (estVARMatrices, _) = VARModel(timeSeriesRDD, p)
</pre>
</div>
</div>

2. We compute the predition residuals.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val residualVAR = VARPredictor(timeSeriesRDD, estVARMatrices, Some(mean))
</pre>
</div>
</div>

3. Let's take a look at the variance - covariance matrix of the residuals. It should be closer to a diagonal matrix than in the univariate analysis.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
val residualSecondMomentVAR = SecondMomentEstimator(residualVAR)
PlotTS.showModel(estVARMatrices, Some("Multivariate parameter estimates"))
PlotTS.showCovariance(residualSecondMomentAR, Some("Monovariate residual covariance"))
PlotTS.showCovariance(residualSecondMomentVAR, Some("Multivariate residual covariance"))
</pre>
</div>
</div>

4. Let's compare the errors between univariate and multivariate models.
<div class="codetabs">
<div data-lang="scala" markdown="1">
<pre class="prettyprint lang-bsh">
println("AR in sample error = " + trace(residualSecondMomentAR))
println("VAR in sample error = " + trace(residualSecondMomentVAR))
println()
</pre> 
</div>
</div>